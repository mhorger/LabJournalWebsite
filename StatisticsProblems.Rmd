---
title: "Statistics Problems"
output:
  html_document:
    toc: true
    toc_float: true
    collapsed: false
    number_sections: false
    toc_depth: 6
    #code_folding: hide
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, warning=FALSE, message = FALSE, eval = FALSE)
```

##Statistics problems 

###Null distribution of mean differences
If you take two random samples from the same distribution they can be different because of random sampling. This question asks you to construct a null-distribution using simulation.

Assume your samples come from a normal distribution with mean =0, sd =1. (use rnorm)
Assume sample size for each sample is n =10 (e.g., rnorm(10,0,1))

```{r}

for(i in 10000)

sample1<- rnorm(10000,0,1)

sample2<- rnorm(10000,0,1)

diff<- sample1 - sample2
```


Create the null-distribution: Run a simulation 10,000 times that finds the difference between means of sample A and B. 

```{r}
counter<-c(0)

for(i in 1:10000){
  sample1<- rnorm(10000,0,1)
  sample2<- rnorm(10000,0,1)
diff[i]<- mean(sample1) - mean(sample2)}

hist(diff)


```



You should have a vector of 10,000 difference scores
Assume an alpha criteria of p<.05 for a directional test. What is the critical value for a positive mean difference? In other words, how large must a positive mean difference be in order to occur less than 5% of the time under the null?


-What does this mean? Our null hypothesis is that the 2 samples are not sig different. The alternative, in this case, is that sample1 is bigger than sample2 thus creating a positive mean difference. 

```{r}
hist(diff, freq = FALSE)

sort(diff) [9500]

diff[9500]


```

Assume an alpha criteria of p<.05 for a non-directional test. What is the critical value for the absolute value of the mean difference. In other words, how large must the absolute value of the mean difference be in order to occur less than 5% of the time under the null?

```{r}
t.test(diff, mu = 0, alternative = "two.sided")

qt(c(.025, .975), df=9999) 


sort(diff)[2500]
sort(diff)[9750]
```




###t-distribution
Show that the properties of a simulated t-distribution are the same as the properties of the analytic t-distribution. Assume df = 9.

-The t distribution has the following properties: The mean of the distribution is equal to 0 . The variance is equal to v / ( v - 2 )

-rt is a random sample of numbers from t dist
-qt function lets us put in the quartiles - getting t value of a p value
-pt function lets us asssess by p values - getting p value of a t value

```{r}
?qt

pt(q = 2, df = 9)



ts <- replicate(10000, t.test(rnorm(10, 0, 1), mu = 0)$statistic)
hist(ts)



length(ts[ts < .5])/10000
length(ts[ts < 1])/10000

tdist_analytic <- rnorm(n = 100000, 0, 1)
hist(tdist_analytic)


```


For example, what are the probabilities of t(9) >= .5, 1, 1.5, 2, and 2.5? These p-values can be obtained using the pt() function.

Create a simulated t-distribution for the null hypothesis with df=9. Here, the model situation involves taking samples of size n=10 from a normal distribution. The t-value is computed for each sample (sample mean - 0)/SEM. The process is repeated 10,000 times, and each t-value is saved. The resulting 10,000 t-values are the simulated t-distribution.

```{r}
pt(q = c(.5, 1, 1.5, 2, 2.5), df = 9)


```


Using the simulated t-distribution, find the probability of t(9) >= .5, 1, 1.5, 2, and 2.5

Compare the two sets of probabilities to show that the difference is small. What happens to the difference if the simulation is repeated fewer times (e.g., 100) vs. more times (e.g., 100,000)

```{r}
tsLESS <- replicate(100, t.test(rnorm(10, 0, 1), mu = 0)$statistic)
hist(tsLESS)

tsMORE <- replicate(100000, t.test(rnorm(10, 0, 1), mu = 0)$statistic)
hist(tsMORE)
```
##Correlation
Sample A and Sample B both have 10 observations randomly sampled from the same normal distribution with mean = 0, and sd =1. The expected correlation between A and B is 0, because both samples are taken randomly.

Generate the distribution of correlations (Pearson r values) that could be obtained by chance (simulate 10,000 times)

Find the critical value such that the absolute value of the correlation occurs less than 5% of the time by chance.

Find the critical value when the sample-size is increased to 100


```{r}
correy<- replicate(100000, cor(rnorm(10, 0, 1), rnorm(10, 0, 1)))
hist(correy)
sort(abs(correy))[95000]


correy100<- replicate(100000, cor(rnorm(100, 0, 1), rnorm(100, 0, 1)))
hist(correy100)
sort(abs(correy100))[95000]
```
You need a correlation of .63 to reject with 10.
You need a correlation of .196 to reject with 100 



##F-values
There are three groups of different subjects. The means for each subject in each group are below. Calculate the F-value for the main effect of group.

```{r}
A <- c(1,2,3,4)
B <- c(3,4,5,6)
C <- c(5,6,7,8)


conds <- rep(c("A", "B", "C"), each = 4)
DV <- c(A, B, C)
df <- data.frame(conds, DV)
summary(aov(DV~conds, df))
```


##F simulation
Assume that there are three groups of different subjects. Each group has four subjects. The subject means for all subjects are sampled randomly from normal distribution with mean =0 and sd =1.

Run a simulation 10,000 times to construct the simulated F-distribution. On each run, sample new numbers into the three groups, then compute F and save it.

Using the simulated F-distribution, what is the critical value of F for alpha set at, p<.05

Compare your answer from above to the answer obtained using qf, that can compute the critical value directly.

```{r}
run_anova <- function (){
Arandom <- rnorm(4, 0, 1)
Brandom <- rnorm(4, 0, 1)
Crandom <-  rnorm(4, 0, 1)

conds <- rep(c("A", "B", "C"), each = 4)
DV <- c(Arandom, Brandom, Crandom)
df <- data.frame(conds, DV)
sum_out<-summary(aov(DV~conds, df))

return(sum_out[[1]]$`F value`[1])
}

save_fs <- replicate(1000, run_anova())
hist(save_fs)

```


